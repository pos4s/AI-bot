# AI-bot (RAG)
## «Разработка AI-бота на базе открытой LLM для абитуриентов «ЛЭТИ»
Объектом разработки является интеллектуальный ассистент для ответов на вопросы абитуриентов на основе документов приемной комиссии. Цель работы – разработать Telegram-бота с использованием LLM, который обеспечит точные ответы на вопросы о правилах поступления в «ЛЭТИ».
Система реализована на языке Python с использованием следующих фреймворков: FastApi – для создания высокопроизводительного backend-сервера, LangChain – для интеграции эмбеддингов и реализации RAG-подхода, Оllama – для локального развертывания LLM. Для многопоточности и асинхронной обработки входящих запросов применена Kafka. Эффективный семантический поиск и кластеризацию плотных векторов реализует FAISS (векторная база данных). Генерацию точных ответов на вопросы абитуриентов даёт открытая языковая модель «mistral:7b-instruct», обеспечивающая высокое качество текстовой генерации при умеренных вычислительных требованиях.
## Реализована оптимизация RAG
>Retrieval-Augmented Generation (RAG) — это гибридный подход к построению систем на базе больших языковых моделей (LLM), который сочетает в себе поиск релевантной информации из внешних источников и генеративное построение ответа. В отличие от классических LLM, работающих исключительно на основе предварительного обучения, архитектура RAG позволяет подключать внешние базы знаний, что существенно повышает точность, актуальность и интерпретируемость ответов.

Для базы знаний были загруженны нормативные документы в векторное хранилище и предварительно разбиты на chunks с overlap

![image](https://github.com/user-attachments/assets/54b40ae0-0bdd-4fee-aee1-e98ed3e62f75)

### LLM
> mistral:7b-instruct (доступна на HuggingFace, но если не хотите использовать внешние API, то эта же модель есть в репозитории Ollama)
## Cредняя семантическая схожесть ответов с эталонными составила 0.84 по метрике косинусного расстояния.
Точность можно увеличить посредством увеличения контекстного окна LLM модели и/или взять модель с бОльшим числом параметров.

![image](https://github.com/user-attachments/assets/0a88693a-9e81-44eb-9f45-9ea9e61459bc)

AI-бот реализовани на CPU 12гб RAM, поэтому если есть GPU, то в device:cpu надо поменять на device:gpu (или cuda если имеется от nvidia)
## Как работает
Для запуска необходимо будет в BotFather в telegram сделать свой токен для создания бота, так же загрузить свой документ для вашей базы знаний
> сначала надо будет запустить файл demo1, затем worker_serviceprocessor1 (если вы запускаете Apache Kafka через docker, то сначала надо будет запустить его)

![image](https://github.com/user-attachments/assets/66dd149a-ad62-474d-ac73-d13703a414fd)

## Результат работы

![image](https://github.com/user-attachments/assets/52636fe8-5025-4836-9fa7-3cb09c71f48f)
![image](https://github.com/user-attachments/assets/152ce157-385c-4297-922f-b5268c1be29c)




